{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  \n",
    "from sklearn.preprocessing import OneHotEncoder      \n",
    "from sklearn.model_selection import KFold   \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib \n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1. LOOK AT THE BIG PICTURE (DONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2. GET THE DATA (DONE). LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(r'dataset/Data.csv')\n",
    "# raw_data.head(10) preview the first 10 column\n",
    "#raw_data.tail() preview the last 10 column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3. DISCOVER THE DATA TO GAIN INSIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for plotting data for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the data for each year\n",
    "def plot_year_data(year):\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax2 = ax.twinx()  # Create a secondary axis for the bar chart\n",
    "\n",
    "    # Plot temperature and feels like as line charts\n",
    "    ax.plot(monthly_avg.index, monthly_avg['temp'][year], label=f'Temp {year}', color='red')\n",
    "    ax.plot(monthly_avg.index, monthly_avg['feelslike'][year], label=f'Feels Like {year}', color='red', linestyle='dashed')\n",
    "\n",
    "    # Plot precipitation as a bar chart\n",
    "    ax2.bar(monthly_avg.index, monthly_avg['precip'][year], color='blue', alpha=0.3, label=f'Precip {year}')\n",
    "\n",
    "    # Set the axis labels and title\n",
    "    ax.set_title(f'Temperature, Feels Like, and Precipitation in {year}')\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('Temperature (°C)', color='red')\n",
    "    ax2.set_ylabel('Precipitation (mm)', color='blue')\n",
    "\n",
    "    # Set custom month labels on the x-axis\n",
    "    ax.set_xticks(range(1, 13))\n",
    "    ax.set_xticklabels(months)\n",
    "\n",
    "    # Add legends outside of the plot area, further right\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.15, 1))\n",
    "    ax2.legend(loc='upper left', bbox_to_anchor=(1.15, 0.85))\n",
    "\n",
    "    # Grid for better readability\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Adjust layout and leave space for the legends\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Quick view of the data\n",
    "print('\\n____________ Dataset info ____________')\n",
    "print(raw_data.info())              \n",
    "print('\\n____________ Some first data examples ____________')\n",
    "print(raw_data.head(5)) \n",
    "print('\\n____________ Counts on a feature ____________')\n",
    "# print(raw_data['LEGAL DOCUMENTS'].value_counts()) \n",
    "print('\\n____________ Statistics of numeric features ____________')\n",
    "print(raw_data.describe())    \n",
    "print('\\n____________ Get specific rows and cols ____________')     \n",
    "print(raw_data.iloc[[0,1,45], [2, 5]] ) # Refer using column ID\n",
    "\n",
    "\n",
    "# Convert 'datetime' column to pandas datetime\n",
    "raw_data['datetime'] = pd.to_datetime(raw_data['datetime'])\n",
    "\n",
    "# Extract the year from the 'datetime' column into a new 'year' column\n",
    "raw_data['year'] = raw_data['datetime'].dt.year\n",
    "\n",
    "# Filter data for the years 2020 to 2024\n",
    "years = [2020, 2021, 2022, 2023, 2024]\n",
    "filtered_data = raw_data[raw_data['year'].isin(years)]\n",
    "\n",
    "# Group the data by year and month, and calculate the average temp, feels like, and precip for each month\n",
    "monthly_avg = filtered_data.groupby([filtered_data['datetime'].dt.month, filtered_data['datetime'].dt.year])[['temp', 'feelslike', 'precip']].mean().unstack(1)\n",
    "\n",
    "# Define month names for the x-axis\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Plot the data for each year separately (2020 to 2023)\n",
    "for year in years[:-1]:  # Exclude 2024\n",
    "    plot_year_data(year)\n",
    "\n",
    "# Plot the data for 2024 in a separate figure\n",
    "plot_year_data(2024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Find features(based on MI) that related to the target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'dataset/Data.csv'  # Adjust the path to your dataset\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Select only the numeric columns from the dataset\n",
    "numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "data_numeric = data[numeric_cols]\n",
    "\n",
    "# Drop rows with missing values (NaN) in the numeric dataset\n",
    "data_numeric_cleaned = data_numeric.dropna()\n",
    "\n",
    "# Prepare the feature set (all numeric features except `temp`)\n",
    "X = data_numeric_cleaned.drop(columns=['temp', 'severerisk', 'precipprob'])  # Drop 'temp' (target variable)\n",
    "y = data_numeric_cleaned['temp']  # Target variable\n",
    "\n",
    "# Step 1: Calculate Mutual Information\n",
    "mi = mutual_info_regression(X, y)\n",
    "\n",
    "# Create a DataFrame for mutual information\n",
    "mi_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Mutual Information': mi\n",
    "}).sort_values(by='Mutual Information', ascending=False)\n",
    "\n",
    "# Print mutual information\n",
    "print(\"Mutual Information between Features and Target:\")\n",
    "print(mi_df)\n",
    "\n",
    "# Step 2: Select top features based on MI (lấy tất cả những chỉ số MI trên 0.25)\n",
    "top_features = mi_df['Feature'].head(8).values ## Có 10 chỉ số MI trên 0.25\n",
    "print(f\"Top features correlate to feature 'temp' based on MI: {top_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.1. Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features to keep\n",
    "features_to_keep = ['feelslike', 'tempmax', 'feelslikemax', 'tempmin', 'feelslikemin', 'dew',\n",
    "                     'sealevelpressure', 'humidity', 'temp']\n",
    "\n",
    "# Drop columns that are not in the list of features to keep\n",
    "raw_data = raw_data[features_to_keep]\n",
    "print(\"Dropped columns successfully. Feature to keeps: \", features_to_keep)\n",
    "# print(raw_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Split-training the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our regression problem, Stratified Sampling is not necessary because the features and target values are continuous rather than categorical. Stratified Sampling is typically used in classification problems to maintain the distribution of target classes across datasets. In regression, where the goal is to predict continuous values, maintaining class proportions is irrelevant and does not impact the model's performance. Therefore, I will focus on data normalization and model optimization to enhance prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "train_set, test_set = train_test_split(raw_data, test_size=0.2, random_state=42)  # Set random_state to get the same training set each time, \n",
    "                                                                                     # otherwise, when repeating training many times, your model might see all the data\n",
    "print('\\n____________ Split training and test set ____________')     \n",
    "print(len(train_set), \"training +\", len(test_set), \"test examples\")\n",
    "print(train_set.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Separate labels from data, since we do not process label values (already processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labels from data\n",
    "X_train = train_set.drop(columns=['temp'])\n",
    "y_train = train_set['temp']\n",
    "X_test = test_set.drop(columns=['temp'])\n",
    "y_test = test_set['temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4. Define pipelines for processing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.1. Define ColumnSelector: a transformer for choosing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    # Hàm khởi tạo nhận vào danh sách các tên cột cần chọn\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names  # Lưu trữ danh sách tên cột\n",
    "\n",
    "    # Phương thức fit không cần thực hiện gì, chỉ trả về chính đối tượng này\n",
    "    # để tương thích với quy trình của scikit-learn\n",
    "    def fit(self, dataframe, labels=None):\n",
    "        return self\n",
    "\n",
    "    # Phương thức transform chọn các cột từ DataFrame dựa trên danh sách tên cột\n",
    "    # và trả về các giá trị dưới dạng mảng NumPy\n",
    "    def transform(self, dataframe):\n",
    "        return dataframe[self.feature_names].values  # Chọn và trả về các cột dưới dạng mảng NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical features\n",
    "num_feat_names = ['feelslike', 'tempmax', 'feelslikemax', 'tempmin', 'feelslikemin', 'dew', 'sealevelpressure', 'humidity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.2.Pipeline for categorical features (IN OUR TRAINING AND TESTING DATASET, THERE ARE NO CATEGORICAL FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.3. KHÔNG CẦN LÀM BƯỚC NÀY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.4. Pipeline for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(num_feat_names)),  # Chọn các cột numeric\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"median\")),  # Điền giá trị thiếu bằng median\n",
    "    ('std_scaler', StandardScaler(with_mean=True, with_std=True))  # Chuẩn hóa về zero mean và unit variance\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.5 Run the pipeline to process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_set_val = num_pipeline.fit_transform(train_set)\n",
    "\n",
    "print('\\n____________ Processed feature values ____________')\n",
    "print(processed_train_set_val[:3, :])  # In ra một vài hàng đầu tiên sau khi xử lý\n",
    "print(processed_train_set_val.shape)  # In ra kích thước của dữ liệu đã xử lý\n",
    "joblib.dump(num_pipeline, r'models/num_pipeline.pkl')   # Lưu pipeline vào file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LƯU Ý: Các giá trị âm trong processed_train_set_val là hoàn toàn hợp lý và thường gặp trong các bài toán học máy, đặc biệt là khi bạn sử dụng chuẩn hóa (scaling) như StandardScaler. Đây là một số lý do và cách giải thích:\n",
    "\n",
    "1. Chuẩn hóa (Standardization):\n",
    "StandardScaler: Bạn đã sử dụng StandardScaler trong pipeline của mình. StandardScaler chuẩn hóa các đặc trưng bằng cách trừ giá trị trung bình và chia cho độ lệch chuẩn, để các đặc trưng có phân phối chuẩn với trung bình bằng 0 và độ lệch chuẩn bằng 1.\n",
    "Kết quả: Sau khi chuẩn hóa, một số giá trị có thể âm, điều này hoàn toàn bình thường. Nếu một giá trị của đặc trưng thấp hơn trung bình của đặc trưng đó, sau khi chuẩn hóa, giá trị đó có thể âm.\n",
    "2. Giá trị âm trong Dữ liệu:\n",
    "Cột dữ liệu: Nếu dữ liệu gốc có giá trị âm (ví dụ như áp suất không khí có thể có giá trị âm trong một số hệ thống đo lường), thì sau khi chuẩn hóa, các giá trị đó có thể vẫn còn âm.\n",
    "3. Ý Nghĩa của Giá trị Âm:\n",
    "Ký hiệu của Chuẩn hóa: Giá trị âm trong kết quả chuẩn hóa chỉ ra rằng giá trị gốc của đặc trưng đó thấp hơn trung bình của đặc trưng đó trong tập dữ liệu. Điều này không có nghĩa là dữ liệu có vấn đề, mà chỉ đơn giản là nó ở dưới mức trung bình.\n",
    "4. Ví dụ:\n",
    "Nếu một đặc trưng X có giá trị trung bình là 100 và độ lệch chuẩn là 15, thì giá trị chuẩn hóa được tính theo công thức: \n",
    "𝑍\n",
    "=\n",
    "𝑋\n",
    "−\n",
    "mean\n",
    "std\n",
    "Z= \n",
    "std\n",
    "X−mean\n",
    "​\n",
    " \n",
    "\n",
    "Nếu X = 85, thì: \n",
    "𝑍\n",
    "=\n",
    "85\n",
    "−\n",
    "100\n",
    "15\n",
    "=\n",
    "−\n",
    "1\n",
    "Z= \n",
    "15\n",
    "85−100\n",
    "​\n",
    " =−1\n",
    "Giá trị chuẩn hóa -1 là hợp lý và có thể xảy ra.\n",
    "Tóm lại:\n",
    "Giá trị âm trong processed_train_set_val là một kết quả bình thường của việc chuẩn hóa dữ liệu và phản ánh sự phân bố dữ liệu gốc so với trung bình. Điều này giúp cải thiện hiệu suất của các mô hình học máy bằng cách đưa tất cả các đặc trưng về cùng một quy mô và phân phối."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train and evaluate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1. Try Light GBM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1.1. Training: Learn a lgbm model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2score_and_rmse(model, train_data, labels): \n",
    "    r2score = model.score(train_data, labels)\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    prediction = model.predict(train_data)\n",
    "    mse = mean_squared_error(labels, prediction)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return r2score, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1.4 Store models to files, to compare latter\n",
    "#from sklearn.externals import joblib \n",
    "import joblib # new lib\n",
    "def store_model(model, model_name = \"\"):\n",
    "    # NOTE: sklearn.joblib faster than pickle of Python\n",
    "    # INFO: can store only ONE object in a file\n",
    "    if model_name == \"\": \n",
    "        model_name = type(model).__name__\n",
    "    joblib.dump(model,'models/' + model_name + '_model.pkl')\n",
    "    print(f\"Model successfully saved as \" + model_name + '_model.pkl')\n",
    "    \n",
    "def load_model(model_name):\n",
    "    # Load objects into memory\n",
    "    #del model\n",
    "    model = joblib.load('models/' + model_name + '_model.pkl')\n",
    "    #print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1. Try Light GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMRegressor() #fix here\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('\\n____________ LGBMRegressor ____________')\n",
    "\n",
    "r2score, rmse = r2score_and_rmse(model, X_train, y_train)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "\n",
    "\n",
    "# Predict labels for some test instances\n",
    "print(\"\\nPredictions: \", model.predict(X_test[:9]).round(decimals=1))\n",
    "print(\"Labels:      \", list(y_test[:9]))\n",
    "\n",
    "store_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2. Try XGB model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Try LTST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
